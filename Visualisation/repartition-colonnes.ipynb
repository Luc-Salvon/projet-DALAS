{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"../Donnees/cleaned_data.csv\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "828027fe",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "id": "353fc8f09f1eb7cf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "number_columns = [\"rating\", \"retirement\", \"time\", \"price\", \"review_count\", \"rating_value\", \"twenty_four_hours\", \"all_time\"]\n",
    "dfn = df[number_columns]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "298a601bf7086142",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "forest = IsolationForest()\n",
    "outliers = forest.fit_predict(dfn)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d1542eec",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "dfn = dfn.drop(index=np.where(outliers==-1)[0])\n",
    "scaler = StandardScaler()  # Standardize numerical variables\n",
    "dfn = pd.DataFrame(scaler.fit_transform(dfn), columns=number_columns)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a828fc022b3e7560",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "sns.pairplot(dfn)\n",
    "plt.savefig(\"pairplot.png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "33b52552",
   "metadata": {},
   "source": [
    "sns.heatmap(dfn.corr(),cmap=\"coolwarm\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8e2b1982",
   "metadata": {},
   "source": [
    "dfn[\"price\"].plot.hist()\n",
    "plt.xlabel(\"Price\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2c4f49d",
   "metadata": {},
   "source": [
    "df['rating'].plot.hist()\n",
    "plt.xlabel(\"Rating\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2bd8b7f7",
   "metadata": {},
   "source": [
    "dfn[\"price\"].plot.box()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "897ab825",
   "metadata": {},
   "source": [
    "df.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "29e2958d",
   "metadata": {},
   "source": [
    "# Traitement des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "id": "ed7a4f84",
   "metadata": {},
   "source": [
    "import ast\n",
    "\n",
    "def dummies_list(df):\n",
    "    df2 = pd.get_dummies(pd.DataFrame(df.values.tolist()), prefix_sep='', prefix='')\n",
    "    merged_columns = {}\n",
    "    for col_name, col_data in df2.items():\n",
    "        if col_name.strip() not in merged_columns:\n",
    "            merged_columns[col_name.strip()] = col_data\n",
    "        else:\n",
    "            merged_columns[col_name.strip()] += col_data\n",
    "    merged_platform = pd.DataFrame(merged_columns)\n",
    "    return merged_platform\n",
    "\n",
    "def X_with_dummies_genres(X):\n",
    "    X = X.dropna(axis=\"rows\")\n",
    "    X['genres'] = X['genres'].astype(str).apply(ast.literal_eval)\n",
    "\n",
    "    X_genre = dummies_list(X.genres)\n",
    "\n",
    "    #X = X.drop(columns=[\"genres\"])\n",
    "\n",
    "    #X = pd.merge(X,X_genre,how = \"left\",left_index=True,right_index=True)\n",
    "\n",
    "    return X_genre\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "49bdfad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T13:21:07.464073Z",
     "start_time": "2024-04-25T13:21:06.994232Z"
    }
   },
   "source": [
    "nb_tags = 150\n",
    "\n",
    "\n",
    "X_genre = X_with_dummies_genres(df)\n",
    "X_genre = X_genre.drop(index=np.where(outliers==-1)[0])\n",
    "colsum = list(zip(X_genre.columns, X_genre.sum()))\n",
    "to_drop = sorted(colsum, key=lambda x:x[1], reverse=True)[nb_tags:]\n",
    "to_drop = [e[0] for e in to_drop]\n",
    "X_genre = X_genre.drop(to_drop, axis=1)\n",
    "X_genre.shape"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k2/pykvndls4t122_sjk529gvvc0000gn/T/ipykernel_14450/2439998991.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['genres'] = X['genres'].astype(str).apply(ast.literal_eval)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2335, 150)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "0a07d8a2",
   "metadata": {},
   "source": [
    "X_genre = X_with_dummies_genres(df)\n",
    "X_genre = X_genre.drop(index=np.where(outliers==-1)[0])\n",
    "\n",
    "\n",
    "# reduction de dimension\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_genre)\n",
    "\n",
    "summary = pd.DataFrame({\"variances\":pca.explained_variance_,\"ratio\":pca.explained_variance_ratio_,\"cumulative ratio\":np.cumsum(pca.explained_variance_ratio_)})\n",
    "(100*summary['cumulative ratio']).plot.bar()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c5a0c2f7",
   "metadata": {},
   "source": [
    "# Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b74c2ef",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "id": "18dbb64b",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(dfn)\n",
    "data = scaler.transform(dfn) # normalisation\n",
    "dataframe = pd.DataFrame(data)\n",
    "pca = PCA()\n",
    "pca.fit(dataframe)\n",
    "\n",
    "summary = pd.DataFrame({\"variances\":pca.explained_variance_,\"ratio\":pca.explained_variance_ratio_,\"cumulative ratio\":np.cumsum(pca.explained_variance_ratio_)})\n",
    "(100*summary['cumulative ratio']).plot.bar()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b733f96",
   "metadata": {},
   "source": [
    "pca_data = pca.transform(dataframe)\n",
    "pca_data = pd.DataFrame(pca_data).drop([5,6,7],axis='columns') # on ne garde que les 3 premières dimensions (80% de l'information)\n",
    "\n",
    "# Cercle de correlation \n",
    "n = data.shape[0] # nb of individuals\n",
    "p = data.shape[1] # nb of variables\n",
    "print(n, '  ', p)\n",
    "eigval = (n-1) / n * pca.explained_variance_ # eigen values\n",
    "sqrt_eigval = np.sqrt(eigval)\n",
    "corvar = np.zeros((p,p)) # empty matrix for coordinates\n",
    "for k in range(p):\n",
    "    corvar[:,k] = pca.components_[k,:] * sqrt_eigval[k]\n",
    "# on modifie pour avoir un dataframe\n",
    "coordvar = pd.DataFrame({'id': dfn.columns, 'COR_1': corvar[:,0], 'COR_2': corvar[:,1]})\n",
    "\n",
    "fig, axes = plt.subplots(figsize = (6,6))\n",
    "fig.suptitle(\"Cercle des corrélations\")\n",
    "axes.set_xlim(-1, 1)\n",
    "axes.set_ylim(-1, 1)\n",
    "# Ajout des axes\n",
    "axes.axvline(x = 0, color = 'lightgray', linestyle = '--', linewidth = 1)\n",
    "axes.axhline(y = 0, color = 'lightgray', linestyle = '--', linewidth = 1)\n",
    "# Ajout des noms des variables\n",
    "for j in range(p):\n",
    "    axes.text(coordvar[\"COR_1\"][j],coordvar[\"COR_2\"][j], coordvar[\"id\"][j])\n",
    "# Ajout du cercle\n",
    "plt.gca().add_artist(plt.Circle((0,0),1,color='blue',fill=False))\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d732013f",
   "metadata": {},
   "source": [
    "plt.scatter(pca_data[0],pca_data[1],s=5)\n",
    "for i in range(pca.components_.shape[1]):\n",
    "    plt.arrow(0,0,pca.components_[0,i]*10,pca.components_[1,i]*10,alpha=0.5)\n",
    "    plt.text(pca.components_[0,i]*10,pca.components_[1,i]*10,dfn.columns[i])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e67f8fc",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "tab20 = plt.get_cmap('tab20')\n",
    "\n",
    "km = KMeans(n_clusters=6)\n",
    "pred = km.fit_predict(data)\n",
    "plt.scatter(pca_data[0],pca_data[1],color = [tab20.colors[pred[i]] for i in range(len(pca_data))],s=5)\n",
    "\n",
    "\n",
    "real_centers = np.exp(pca.inverse_transform(km.cluster_centers_))\n",
    "fig, axs = plt.subplots(km.n_clusters//2, 2, sharey=True,sharex=True)\n",
    "for i,k in enumerate(real_centers):\n",
    "    axs.flatten()[i].bar(range(len(k)),k,color=tab20.colors[i])\n",
    "    axs.flatten()[i].set_xticks(range(len(k)))\n",
    "    axs.flatten()[i].set_xticklabels(dfn.columns,rotation=\"vertical\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "40c66f15",
   "metadata": {},
   "source": [
    "### Prédiction du rating en fonction du genre, de la platforme, de la date de sortie et du prix."
   ]
  },
  {
   "cell_type": "code",
   "id": "f7fa5da7",
   "metadata": {},
   "source": [
    "\n",
    "def X_with_dummies_genre_platform(X):\n",
    "    X = X.dropna(axis=\"rows\")\n",
    "    X['platform'] = X['platform'].astype(str).apply(ast.literal_eval) # certaines listes sont enregistrées en str donc on remet tout en listes\n",
    "    X['genre'] = X['genre'].astype(str).apply(ast.literal_eval)\n",
    "\n",
    "    X_platform = dummies_list(X.platform)\n",
    "    X_genre = dummies_list(X.genre)\n",
    "\n",
    "    X = X.drop(columns=[\"platform\",\"genre\"])\n",
    "\n",
    "    X = pd.merge(X,X_platform,how = \"left\",left_index=True,right_index=True)\n",
    "    X = pd.merge(X,X_genre,how = \"left\",left_index=True,right_index=True)\n",
    "\n",
    "    return X"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cc4c0295",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "X = df[['platform', 'genre', 'date', 'price', \"time\"]]\n",
    "y = df['rating']\n",
    "X = X_with_dummies_genre_platform(X)\n",
    "X = X.drop(index=np.where(outliers==-1)[0])\n",
    "y = y.drop(index=np.where(outliers==-1)[0])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train = list(y_train)\n",
    "y_test = list(y_test)\n",
    "\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "#model = Ridge()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R-squared: {r2}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8cca7c3e",
   "metadata": {},
   "source": [
    "### Prédiction du retirement en fonction du rating, de la plateforme, du genre, de la date et du prix"
   ]
  },
  {
   "cell_type": "code",
   "id": "fd151d03",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Preprocessing\n",
    "X = df[['rating',\"pourcentage_pos\", 'platform', 'genre', 'date', 'price','time',\"twenty_four_hours\",\"all_time\"]]\n",
    "y = df['retirement']\n",
    "\n",
    "X = X_with_dummies_genre_platform(X)\n",
    "\n",
    "X = X.drop(index=np.where(outliers==-1)[0])\n",
    "y = y.drop(index=np.where(outliers==-1)[0])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict retirement on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2e57b1a4",
   "metadata": {},
   "source": [
    "## Clusters"
   ]
  },
  {
   "cell_type": "code",
   "id": "2ea59574",
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = df[['platform', 'genre', 'rating']]\n",
    "X = X_with_dummies_genre_platform(X)\n",
    "#scaler = StandardScaler()  # Standardize numerical variables\n",
    "#X_scaled = scaler.fit_transform(X_encoded)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88b9f62e",
   "metadata": {},
   "source": [
    "# t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tab20 = plt.get_cmap('tab20')\n",
    "\n",
    "km = KMeans(n_clusters=5)\n",
    "km.n_clusters = 8\n",
    "pred = km.fit_predict(X)\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne_data = tsne.fit_transform(X)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(tsne_data[:, 0], tsne_data[:, 1], c=pred, cmap='tab20', s=10)\n",
    "plt.title('t-SNE Visualization')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
